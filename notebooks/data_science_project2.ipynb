{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d07320-dde7-4564-9578-3a26d0d57aa7",
   "metadata": {},
   "source": [
    "## Predicting Price with Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc63a6-3041-40fd-99fa-9a27c774ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression #build a model\n",
    "from sklearn.metrics import mean_absolute_error #evaluate a model\n",
    "from sklearn.utils.validation import check_is_fitted #validate our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e25a0-6ea0-4516-a1cc-3b7bba3f7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this project, you're working for a client who wants to create a model that can predict the price of apartments in the city of Buenos Aires — with a focus on apartments that cost less than $400,000 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422e751-dcfc-4597-b371-33b98995904a",
   "metadata": {},
   "source": [
    " Write a function named wrangle that takes a file path as an argument and returns a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad72154-97ba-43dd-a67c-32d6ba05fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "    #reading the data into a csv file\n",
    "    df=pd.read_csv(filepath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80488095-941f-46e8-8b1b-f545536d5b05",
   "metadata": {},
   "source": [
    "Now that we have a function written, let's test it out on one of the CSV files we'll use in this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97302ea6-65dd-4ad0-9be9-deed9d3124d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/buenos-aires-real-estate-1.csv\")\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe0550-9db1-47a9-a4d6-aff85c4b464b",
   "metadata": {},
   "source": [
    "At this point, your DataFrame df should have no more than 8,606 observations. check using assert function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da44f6-9c20-4d16-afb6-a63cfea0f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert (\n",
    "    len(df) <= 8606\n",
    "), f\"`df` should have no more than 8606 observations, not {len(df)}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44318f3-cb2f-4f74-b78f-17925d0d5f38",
   "metadata": {},
   "source": [
    "Task 2.1.3: Add to your wrangle function so that the DataFrame it returns only includes apartments in Buenos Aires (\"Capital Federal\") that cost less than $400,000 USD. Then recreate df from data/buenos-aires-real-estate-1.csv by re-running the cells above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4ce3e-d5c2-418c-b569-d98e17311104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "    #reading the data into a csv file\n",
    "    df=pd.read_csv(filepath)\n",
    "    #subsetting properties in \"Capital Federal\"\n",
    "    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
    "    #subsetting \"apartment\"\n",
    "    mask_apt=df[\"property_type\"]==\"apartment\"\n",
    "    #subset where \"price_aprox_usd\" < 400000\n",
    "    mask_price=df[\"price_aprox_usd\"] < 400000\n",
    "    df=df[mask_ba & mask_apt & mask_price]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2988ac-7ca4-4f3e-939c-999ad8bf2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/buenos-aires-real-estate-1.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fbb28-2348-4244-b1e0-f05060c1e36b",
   "metadata": {},
   "source": [
    "To check your work, df should no have no more than 1,781 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c8bf3-0527-48af-a514-c106f0ce49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert (\n",
    "    len(df) <= 1781\n",
    "), f\"`df` should have no more than 1781 observations, not {len(df)}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fac067-4afe-4c4b-ae02-0058fd75015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##histogram results show presence of outliers\n",
    "plt.hist(df[\"surface_covered_in_m2\"])\n",
    "plt.xlabel(\"Area [sq meters]\")\n",
    "plt.title(\"Distribution of Apartment Sizes\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9d93b-17d2-497c-9999-56ef0fd83363",
   "metadata": {},
   "outputs": [],
   "source": [
    "## summary statistics for the \"surface_covered_in_m2\" feature. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb728c05-6711-4b2a-969b-6698e08729fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "\n",
    "    #reading the data into a csv file\n",
    "\n",
    "    df=pd.read_csv(filepath)\n",
    "\n",
    "    #subsetting properties in \"Capital Federal\"\n",
    "\n",
    "    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
    "\n",
    "    #subsetting \"apartment\"\n",
    "\n",
    "    mask_apt=df[\"property_type\"]==\"apartment\"\n",
    "\n",
    "    #subset where \"price_aprox_usd\" < 400000\n",
    "\n",
    "    mask_price=df[\"price_aprox_usd\"] < 400000\n",
    "\n",
    "    df=df[mask_ba & mask_apt & mask_price]\n",
    "    # removing outliers by filtering the surface_covered_in_m2\n",
    "    low,high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n",
    "    mask_area = df[\"surface_covered_in_m2\"].between(low,high)\n",
    "    df = df[mask_area]\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cc111-b0cf-4354-8d40-664d824da290",
   "metadata": {},
   "source": [
    "Correlation between price and area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a23dd7-42d6-4a87-9f83-d8e599d0673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df[\"surface_covered_in_m2\"],y=df[\"price_aprox_usd\"])\n",
    "plt.xlabel(\"Area [sq meters]\")\n",
    "plt.ylabel(\"Price [USD]\")\n",
    "plt.title(\"Bueno Aires: Price vs. Area\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7465cbae-deb1-4bb2-b7f3-ed935c499063",
   "metadata": {},
   "source": [
    "## Splitting feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92777179-05fb-46ee-a16a-45a3b6ed5680",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"surface_covered_in_m2\"]\n",
    "X_train = df[features]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efb233-d257-4c6e-b6b3-49d8c1650cbf",
   "metadata": {},
   "source": [
    "Fit a linear regression model to the mexico-city-real-estate-2.csv data set to relate \"price_aprox_usd\" and \"surface_covered_in_m2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa49df7-ed43-4c26-808c-982874e1c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "columns = [\"price_aprox_usd\", \"surface_covered_in_m2\"]\n",
    "mexico_city2 = pd.read_csv(\"data/mexico-city-real-estate-2.csv\",usecols=columns)\n",
    "# Drop rows with missing values\n",
    "mexico_city2.dropna(inplace=True)\n",
    "\n",
    "# Split data into feature matrix\n",
    "X = mexico_city2[[\"surface_covered_in_m2\"]]\n",
    "y = mexico_city2[\"price_aprox_usd\"]\n",
    "\n",
    "# Instantiate predictor\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit predictor to data\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec46bd0-4457-443c-875b-e5f4bfd9bbde",
   "metadata": {},
   "source": [
    "Read the data from mexico-city-real-estate-4.csv into a DataFrame and then generate a list of price predictions for the properties using your model lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062cb01e-ea81-4e92-b081-2ab5c497d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "mexico_city4 = pd.read_csv(\"data/mexico-city-real-estate-4.csv\",usecols=[\"surface_covered_in_m2\"])\n",
    "\n",
    "# Drop missing values\n",
    "mexico_city4.dropna(inplace=True)\n",
    "\n",
    "# Generate predictions\n",
    "price_pred = lr.predict(mexico_city4)\n",
    "\n",
    "# Print predictions\n",
    "price_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ad89c-8851-4c8c-b48f-cb767dede92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://youtu.be/Q81RR3yKn30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9320e1-db49-4542-b2eb-1c0a1fab69dc",
   "metadata": {},
   "source": [
    "Ridge Regression\n",
    "\n",
    "Sometimes,the values for coefficients and the intercept - both positive and negative - are very large. When you see this in a linear model — especially a high-dimensional model — what's happening is that the model is overfitting to the training data and then can't generalize to the test data. Some people call this the curse of dimensionality. ☠️\n",
    "\n",
    "The way to solve this problem is to use regularization, a group of techniques that prevent overfitting. In this case, we'll change the predictor from LinearRegression to Ridge, which is a linear regressor with an added tool for keeping model coefficients from getting too big."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6072ed6-41df-4b34-a2d0-d87cd08d29bd",
   "metadata": {},
   "source": [
    "Calculating the Mean Absolute Error for a List of Predictions\n",
    "\n",
    "Plots are great for displaying information, but a value that tells you the typical error in a prediction is helpful too. This value is called the mean absolute error, and it's defined as the average value of the magnitude of the error in the predictions. The closer the MAE is to 0, the better our model fits the data. scikit-learn will do this for you if you pass it the price predictions from your regression model and the actual prices from the test data set. Let's see how our lr model did by comparing its predictions to the true values in mexico_city_labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbf7b6-16f8-4cbc-8fef-98014f24b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(price_pred_example, mexico_city_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd10a65-dced-4df5-845c-5e7077982ea4",
   "metadata": {},
   "source": [
    "Access an Attribute of a Trained Model\n",
    "\n",
    "After training a model that fits a straight line to your data, you can now obtain the parameters that fit your line. We're particularly interested in the slope regr_lr.coef_ and the axis intercept regr_lr.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58efea-6d67-4e81-9046-1f9ec0a08eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3735fe-8a6d-4911-9b65-7dfc09150ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbd3de-2a12-4b5f-b6ae-777be3a7e187",
   "metadata": {},
   "source": [
    "Multicollinearity\n",
    "\n",
    "When you're creating a linear model that uses many features to make predictions, some of those features can be highly correlated with each other. This isn't a problem that's going to break your model; it will still make predictions and it might have good performance metrics. But it is an issue if you want to interpret the coefficients for your model because it becomes hard to tell which features are truly important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180acf5e-06ff-4227-9c98-e77dcb8d8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import data\n",
    "columns = [\n",
    "    \"price\",\n",
    "    \"price_aprox_local_currency\",\n",
    "    \"price_aprox_usd\",\n",
    "    \"surface_total_in_m2\",\n",
    "    \"surface_covered_in_m2\",\n",
    "    \"price_per_m2\",\n",
    "]\n",
    "mexico_city1 = pd.read_csv(\"./data/mexico-city-real-estate-1.csv\", usecols=columns)\n",
    "\n",
    "# Drop missing values\n",
    "mexico_city1.dropna(inplace=True)\n",
    "\n",
    "mexico_city1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c0f30-b0c5-45a0-8697-8acee092caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mexico_city1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a01a58-d852-48cc-9ff1-0be5fd36cc62",
   "metadata": {},
   "source": [
    " fit a linear regression model for surface_covered_in_m2 as a function of price_aprox_usd and price_aprox_local_currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3058e6-e02a-4373-8705-dc97f6c85166",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(\n",
    "    mexico_city1[[\"price_aprox_usd\", \"price_aprox_local_currency\"]],\n",
    "    mexico_city1[\"surface_covered_in_m2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ccb9d2-0005-4f13-90b5-851558d29a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ccf2b1-8a3d-44e1-b35f-cc6677b0bf5b",
   "metadata": {},
   "source": [
    " We need to remove columns first, before removing the rows; the sequence of operations here is important. The code looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f922e5-71d5-4f98-b9f7-3c6a14065549",
   "metadata": {},
   "outputs": [],
   "source": [
    "mexico_city1 = mexico_city1.drop(\n",
    "    [\"floor\", \"price_usd_per_m2\", \"expenses\", \"rooms\"], axis=1\n",
    ")\n",
    "mexico_city1 = mexico_city1.dropna(axis=0)\n",
    "mexico_city1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db8c81-37dd-4cb5-9996-345ca0e2ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee9833-4dfe-4c1c-ade2-7dbdcbb3eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"price_aprox_usd\"\n",
    "y_train = df[target]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07610726-599f-4827-835a-e9380cec5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64289cb2-8b89-4cde-82b9-6012b0f14d36",
   "metadata": {},
   "source": [
    "Baseline\n",
    "One way to think about this is to see how a \"dumb\" model would perform on the same data. Some people also call this a naïve or baseline model, but it's always a model makes only one prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676a012-bc3a-42aa-a88f-9c91a8578164",
   "metadata": {},
   "source": [
    "Calculate the mean of your target vector y_train and assign it to the variable y_mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3828e1-5615-455e-b22c-89bdcba6d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = y_train.mean()\n",
    "y_mean ##the predicted value of a naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0add4f2-e30d-4a4c-a231-a7f065c54d1f",
   "metadata": {},
   "source": [
    "In machine learning, a regression problem is when you need to build a model that's going to predict a continuous, numerical value, like the sale price of an apartment. One of the models that you can use for regression problems is called linear regression. In it's simplest form, we fit a model that will predict a single output variable (called a target vector) as a linear function of a single input variable (called a feature matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664714b-07e3-4a7a-b2a2-c5fc654e83bb",
   "metadata": {},
   "source": [
    " Add a line to the plot below that shows the relationship between the observations X_train and our dumb model's predictions y_pred_baseline. Be sure that the line color is orange, and that it has the label \"Baseline Model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72232fb3-8989-4a88-992c-03ca8fe4e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train, y_pred_baseline, color=\"orange\", label=\"Baseline Model\")\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel(\"Area [sq meters]\")\n",
    "plt.ylabel(\"Price [USD]\")\n",
    "plt.title(\"Buenos Aires: Price vs. Area\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0482b-ef86-4c22-9797-dbd91713df7b",
   "metadata": {},
   "source": [
    "Calculate the baseline mean absolute error for your predictions in y_pred_baseline as compared to the true targets in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ed696-7ab4-4d37-942b-6d0a72284805",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
    "\n",
    "print(\"Mean apt price\", round(y_mean, 2))\n",
    "print(\"Baseline MAE:\", round(mae_baseline, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045567be-5528-4e0a-95db-201338c609d0",
   "metadata": {},
   "source": [
    "Iterate\n",
    "\n",
    "The next step in building a model is iterating. This involves building a model, training it, evaluating it, and then repeating the process until you're happy with the model's performance. Even though the model we're building is linear, the iteration process rarely follows a straight line. Be prepared for trying new things, hitting dead-ends, and waiting around while your computer does long computations to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294692a-1c5e-4dd5-aae1-dceaf6c480c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()# instantiating a model\n",
    "model.fit(X_train,y_train)# fitting the model\n",
    "# Check if the model is fitted\n",
    "#check_is_fitted(model)\n",
    "y_pred_training = model.predict(X_train)#Making predictions using tje training set\n",
    "#y_pred_training[:5]\n",
    "mae_training = mean_absolute_error(y_train,y_pred_training)#evaluating using the man absolute error\n",
    "#print(\"Training MAE:\", round(mae_training, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca4f91-dafb-43e0-a18d-3412abaceb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##making prediction on the test data\n",
    "X_test = pd.read_csv(\"data/buenos-aires-test-features.csv\")[features]\n",
    "y_pred_test = pd.Series(model.predict(X_test))\n",
    "y_pred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2477919-4490-43ef-b66f-e2d1fb382482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intercept of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e376ad-2533-449a-92ea-dd072d3d4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = round(model.intercept_,2)\n",
    "print(\"Model Intercept:\", intercept)\n",
    "assert any([isinstance(intercept, int), isinstance(intercept, float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df29fdd-f17e-4c0a-ad75-ce44c8deb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficient of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be19aa-d468-46c6-b71a-20ab05ef12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = round(model.intercept_,2)\n",
    "print(\"Model Intercept:\", intercept)\n",
    "assert any([isinstance(intercept, int), isinstance(intercept, float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7951d-21b8-45e6-8871-562befc70241",
   "metadata": {},
   "outputs": [],
   "source": [
    "##generating an equation\n",
    "print(f\"apt_price = {intercept} + {coefficient} * surface_covered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8622b8-63bc-44f9-8f43-1b29013cfd3c",
   "metadata": {},
   "source": [
    "Add a line to the plot below that shows the relationship between the observations in X_train and your model's predictions y_pred_training. Be sure that the line color is red, and that it has the label \"Linear Model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148767b-d4d3-4a47-9e2b-be657d3ffddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train, model.predict(X_train),color=\"r\",label=\"Linear Model\")\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel(\"surface covered [sq meters]\")\n",
    "plt.ylabel(\"price [usd]\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3315bb-f7c8-49ad-a83c-10fb67824e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
